/var/tmp/slurmd_spool/job972392/slurm_script: line 13: module: command not found
2025-01-13 14:51:54,707 - INFO - Testing model: gpt2
2025-01-13 14:51:54,712 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-01-13 14:54:05,214 - DEBUG - Starting new HTTPS connection (2): huggingface.co:443
2025-01-13 14:56:05,681 - DEBUG - Loaded model and tokenizer for gpt2
2025-01-13 14:56:05,682 - INFO - Running layer identification experiment for model: gpt2
2025-01-13 14:56:05,683 - DEBUG - Starting new HTTPS connection (3): huggingface.co:443
2025-01-13 14:58:05,837 - DEBUG - Starting new HTTPS connection (1): s3.amazonaws.com:443
2025-01-13 14:58:29,872 - DEBUG - Starting new HTTPS connection (1): datasets-server.huggingface.co:443
2025-01-13 15:05:10,295 - DEBUG - Starting new HTTPS connection (2): s3.amazonaws.com:443
2025-01-13 15:05:34,331 - DEBUG - Starting new HTTPS connection (4): huggingface.co:443
Using the latest cached version of the module from /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed (last modified on Thu Jan  9 11:51:10 2025) since it couldn't be found locally at super_glue, or remotely on the Hugging Face Hub.
2025-01-13 15:07:34,470 - WARNING - Using the latest cached version of the module from /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed (last modified on Thu Jan  9 11:51:10 2025) since it couldn't be found locally at super_glue, or remotely on the Hugging Face Hub.
2025-01-13 15:07:34,474 - DEBUG - Attempting to acquire lock 139874873765120 on /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue.lock
2025-01-13 15:07:34,496 - DEBUG - Lock 139874873765120 acquired on /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue.lock
2025-01-13 15:07:34,539 - DEBUG - Attempting to release lock 139874873765120 on /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue.lock
2025-01-13 15:07:34,539 - DEBUG - Lock 139874873765120 released on /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue.lock
2025-01-13 15:07:34,598 - DEBUG - Attempting to acquire lock 139874262190832 on /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/_home_hpc_iwi5_iwi5268h_.cache_huggingface_datasets_super_glue_wic_1.0.3_bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed.lock
2025-01-13 15:07:34,624 - DEBUG - Lock 139874262190832 acquired on /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/_home_hpc_iwi5_iwi5268h_.cache_huggingface_datasets_super_glue_wic_1.0.3_bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed.lock
2025-01-13 15:07:34,629 - DEBUG - open file: /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/dataset_info.json
2025-01-13 15:07:34,631 - DEBUG - Attempting to release lock 139874262190832 on /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/_home_hpc_iwi5_iwi5268h_.cache_huggingface_datasets_super_glue_wic_1.0.3_bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed.lock
2025-01-13 15:07:34,632 - DEBUG - Lock 139874262190832 released on /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/_home_hpc_iwi5_iwi5268h_.cache_huggingface_datasets_super_glue_wic_1.0.3_bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed.lock
2025-01-13 15:07:35,047 - DEBUG - Attempting to acquire lock 139874871850416 on /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue.lock
2025-01-13 15:07:35,048 - DEBUG - Lock 139874871850416 acquired on /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue.lock
2025-01-13 15:07:35,091 - DEBUG - Attempting to release lock 139874871850416 on /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue.lock
2025-01-13 15:07:35,092 - DEBUG - Lock 139874871850416 released on /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue.lock
2025-01-13 15:07:35,092 - DEBUG - Attempting to acquire lock 139874873627216 on /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed_builder.lock
2025-01-13 15:07:35,126 - DEBUG - Lock 139874873627216 acquired on /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed_builder.lock
2025-01-13 15:07:35,126 - DEBUG - open file: /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/dataset_info.json
2025-01-13 15:07:35,128 - DEBUG - Attempting to release lock 139874873627216 on /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed_builder.lock
2025-01-13 15:07:35,129 - DEBUG - Lock 139874873627216 released on /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed_builder.lock
2025-01-13 15:07:35,625 - DEBUG - Loaded and prepared dataset: wic, split: train
2025-01-13 15:07:35,657 - DEBUG - Processing layer 0
/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
2025-01-13 15:11:59,168 - INFO - Layer 0 - Accuracy: 0.639, F1 Score: 0.639
2025-01-13 15:11:59,168 - DEBUG - Processing layer 1
2025-01-13 15:14:07,604 - INFO - Layer 1 - Accuracy: 0.609, F1 Score: 0.609
2025-01-13 15:14:07,605 - DEBUG - Processing layer 2
2025-01-13 15:15:44,058 - WARNING - Skipping Layer 2 due to shape mismatch: torch.Size([1, 69, 768])
2025-01-13 15:15:44,061 - DEBUG - Processing layer 3
2025-01-13 15:17:48,222 - INFO - Layer 3 - Accuracy: 0.610, F1 Score: 0.610
2025-01-13 15:17:48,223 - DEBUG - Processing layer 4
2025-01-13 15:19:26,463 - ERROR - Error processing Layer 4: 4
2025-01-13 15:19:26,467 - DEBUG - Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/LLM-RSA-Project/experiments/probing_experiments.py", line 44, in run_layer_identification_experiment
    layer_activations = activations[layer_idx]
KeyError: 4

2025-01-13 15:19:26,467 - DEBUG - Processing layer 5
2025-01-13 15:21:42,087 - INFO - Layer 5 - Accuracy: 0.626, F1 Score: 0.626
2025-01-13 15:21:42,088 - DEBUG - Processing layer 6
2025-01-13 15:23:31,316 - INFO - Layer 6 - Accuracy: 0.623, F1 Score: 0.623
2025-01-13 15:23:31,316 - DEBUG - Processing layer 7
/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
2025-01-13 15:29:25,151 - INFO - Layer 7 - Accuracy: 0.585, F1 Score: 0.585
2025-01-13 15:29:25,151 - DEBUG - Processing layer 8
2025-01-13 15:32:50,237 - INFO - Layer 8 - Accuracy: 0.602, F1 Score: 0.602
2025-01-13 15:32:50,238 - DEBUG - Processing layer 9
/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
2025-01-13 15:36:08,284 - INFO - Layer 9 - Accuracy: 0.585, F1 Score: 0.585
2025-01-13 15:36:08,284 - DEBUG - Processing layer 10
2025-01-13 15:37:44,316 - ERROR - Error processing Layer 10: 10
2025-01-13 15:37:44,318 - DEBUG - Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/LLM-RSA-Project/experiments/probing_experiments.py", line 44, in run_layer_identification_experiment
    layer_activations = activations[layer_idx]
KeyError: 10

2025-01-13 15:37:44,318 - DEBUG - Processing layer 11
/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
2025-01-13 15:40:28,017 - INFO - Layer 11 - Accuracy: 0.585, F1 Score: 0.585
2025-01-13 15:40:28,019 - INFO - Testing model: gpt-neo-1.3B
2025-01-13 15:40:28,023 - DEBUG - Starting new HTTPS connection (5): huggingface.co:443
2025-01-13 15:42:28,159 - DEBUG - Starting new HTTPS connection (6): huggingface.co:443
2025-01-13 15:44:28,290 - ERROR - Failed to test model gpt-neo-1.3B: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like gpt-neo-1.3B is not the path to a directory containing a file named config.json.
Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.
2025-01-13 15:44:28,593 - DEBUG - Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
socket.timeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 488, in _make_request
    raise new_e
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 1093, in _validate_conn
    conn.connect()
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connection.py", line 704, in connect
    self.sock = sock = self._new_conn()
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connection.py", line 207, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x7f372800be80>, 'Connection to huggingface.co timed out. (connect timeout=10)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /gpt-neo-1.3B/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f372800be80>, 'Connection to huggingface.co timed out. (connect timeout=10)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1374, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1294, in get_hf_file_metadata
    r = _request_wrapper(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 278, in _request_wrapper
    response = _request_wrapper(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 301, in _request_wrapper
    response = get_session().request(method=method, url=url, **params)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/utils/_http.py", line 93, in send
    return super().send(request, *args, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/adapters.py", line 688, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /gpt-neo-1.3B/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f372800be80>, 'Connection to huggingface.co timed out. (connect timeout=10)'))"), '(Request ID: 2799dfec-d4b8-424f-94e6-2f11db505082)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 860, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 967, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1485, in _raise_on_head_call_error
    raise LocalEntryNotFoundError(
huggingface_hub.errors.LocalEntryNotFoundError: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/LLM-RSA-Project/run_experiments.py", line 45, in main
    model, tokenizer = load_model_and_tokenizer(model_name)
  File "/home/hpc/iwi5/iwi5268h/LLM-RSA-Project/models/models.py", line 6, in load_model_and_tokenizer
    model = AutoModel.from_pretrained(model_name)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 526, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py", line 1021, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/configuration_utils.py", line 590, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/configuration_utils.py", line 649, in _get_config_dict
    resolved_config_file = cached_file(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/utils/hub.py", line 446, in cached_file
    raise EnvironmentError(
OSError: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like gpt-neo-1.3B is not the path to a directory containing a file named config.json.
Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.

2025-01-13 15:44:28,593 - INFO - Testing model: gpt-j-6B
2025-01-13 15:44:28,595 - DEBUG - Starting new HTTPS connection (7): huggingface.co:443
2025-01-13 15:46:28,722 - DEBUG - Starting new HTTPS connection (8): huggingface.co:443
2025-01-13 15:48:28,846 - ERROR - Failed to test model gpt-j-6B: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like gpt-j-6B is not the path to a directory containing a file named config.json.
Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.
2025-01-13 15:48:28,855 - DEBUG - Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
socket.timeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 488, in _make_request
    raise new_e
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 1093, in _validate_conn
    conn.connect()
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connection.py", line 704, in connect
    self.sock = sock = self._new_conn()
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connection.py", line 207, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x7f372808f670>, 'Connection to huggingface.co timed out. (connect timeout=10)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /gpt-j-6B/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f372808f670>, 'Connection to huggingface.co timed out. (connect timeout=10)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1374, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1294, in get_hf_file_metadata
    r = _request_wrapper(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 278, in _request_wrapper
    response = _request_wrapper(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 301, in _request_wrapper
    response = get_session().request(method=method, url=url, **params)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/utils/_http.py", line 93, in send
    return super().send(request, *args, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/adapters.py", line 688, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /gpt-j-6B/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f372808f670>, 'Connection to huggingface.co timed out. (connect timeout=10)'))"), '(Request ID: 39dc8454-e9c7-44df-bf6a-e5ae3de3f48b)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 860, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 967, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1485, in _raise_on_head_call_error
    raise LocalEntryNotFoundError(
huggingface_hub.errors.LocalEntryNotFoundError: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/LLM-RSA-Project/run_experiments.py", line 45, in main
    model, tokenizer = load_model_and_tokenizer(model_name)
  File "/home/hpc/iwi5/iwi5268h/LLM-RSA-Project/models/models.py", line 6, in load_model_and_tokenizer
    model = AutoModel.from_pretrained(model_name)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 526, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py", line 1021, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/configuration_utils.py", line 590, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/configuration_utils.py", line 649, in _get_config_dict
    resolved_config_file = cached_file(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/utils/hub.py", line 446, in cached_file
    raise EnvironmentError(
OSError: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like gpt-j-6B is not the path to a directory containing a file named config.json.
Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.

2025-01-13 15:48:28,855 - INFO - Testing model: decapoda-research/llama-7b-hf
2025-01-13 15:48:28,857 - DEBUG - Starting new HTTPS connection (9): huggingface.co:443
2025-01-13 15:50:28,989 - DEBUG - Starting new HTTPS connection (10): huggingface.co:443
2025-01-13 15:52:29,114 - ERROR - Failed to test model decapoda-research/llama-7b-hf: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like decapoda-research/llama-7b-hf is not the path to a directory containing a file named config.json.
Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.
2025-01-13 15:52:29,122 - DEBUG - Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
socket.timeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 488, in _make_request
    raise new_e
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 1093, in _validate_conn
    conn.connect()
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connection.py", line 704, in connect
    self.sock = sock = self._new_conn()
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connection.py", line 207, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x7f372827d280>, 'Connection to huggingface.co timed out. (connect timeout=10)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /decapoda-research/llama-7b-hf/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f372827d280>, 'Connection to huggingface.co timed out. (connect timeout=10)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1374, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1294, in get_hf_file_metadata
    r = _request_wrapper(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 278, in _request_wrapper
    response = _request_wrapper(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 301, in _request_wrapper
    response = get_session().request(method=method, url=url, **params)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/utils/_http.py", line 93, in send
    return super().send(request, *args, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/adapters.py", line 688, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /decapoda-research/llama-7b-hf/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f372827d280>, 'Connection to huggingface.co timed out. (connect timeout=10)'))"), '(Request ID: ebf046e1-7b59-4656-8c0d-f2c3d148cb38)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 860, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 967, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1485, in _raise_on_head_call_error
    raise LocalEntryNotFoundError(
huggingface_hub.errors.LocalEntryNotFoundError: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/LLM-RSA-Project/run_experiments.py", line 45, in main
    model, tokenizer = load_model_and_tokenizer(model_name)
  File "/home/hpc/iwi5/iwi5268h/LLM-RSA-Project/models/models.py", line 6, in load_model_and_tokenizer
    model = AutoModel.from_pretrained(model_name)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 526, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py", line 1021, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/configuration_utils.py", line 590, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/configuration_utils.py", line 649, in _get_config_dict
    resolved_config_file = cached_file(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/utils/hub.py", line 446, in cached_file
    raise EnvironmentError(
OSError: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like decapoda-research/llama-7b-hf is not the path to a directory containing a file named config.json.
Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.

2025-01-13 15:52:29,122 - INFO - Testing model: meta-llama/Llama-2-7b-hf
2025-01-13 15:52:29,124 - DEBUG - Starting new HTTPS connection (11): huggingface.co:443
2025-01-13 15:54:29,259 - DEBUG - Starting new HTTPS connection (12): huggingface.co:443
2025-01-13 15:56:29,391 - ERROR - Failed to test model meta-llama/Llama-2-7b-hf: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like meta-llama/Llama-2-7b-hf is not the path to a directory containing a file named config.json.
Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.
2025-01-13 15:56:29,399 - DEBUG - Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
socket.timeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 488, in _make_request
    raise new_e
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 1093, in _validate_conn
    conn.connect()
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connection.py", line 704, in connect
    self.sock = sock = self._new_conn()
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connection.py", line 207, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x7f373bba0dc0>, 'Connection to huggingface.co timed out. (connect timeout=10)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /meta-llama/Llama-2-7b-hf/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f373bba0dc0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1374, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1294, in get_hf_file_metadata
    r = _request_wrapper(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 278, in _request_wrapper
    response = _request_wrapper(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 301, in _request_wrapper
    response = get_session().request(method=method, url=url, **params)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/utils/_http.py", line 93, in send
    return super().send(request, *args, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/adapters.py", line 688, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /meta-llama/Llama-2-7b-hf/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f373bba0dc0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))"), '(Request ID: 53ad5fd5-981d-471c-bec6-e252db364dc7)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 860, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 967, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1485, in _raise_on_head_call_error
    raise LocalEntryNotFoundError(
huggingface_hub.errors.LocalEntryNotFoundError: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/LLM-RSA-Project/run_experiments.py", line 45, in main
    model, tokenizer = load_model_and_tokenizer(model_name)
  File "/home/hpc/iwi5/iwi5268h/LLM-RSA-Project/models/models.py", line 6, in load_model_and_tokenizer
    model = AutoModel.from_pretrained(model_name)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 526, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py", line 1021, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/configuration_utils.py", line 590, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/configuration_utils.py", line 649, in _get_config_dict
    resolved_config_file = cached_file(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/utils/hub.py", line 446, in cached_file
    raise EnvironmentError(
OSError: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like meta-llama/Llama-2-7b-hf is not the path to a directory containing a file named config.json.
Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.

2025-01-13 15:56:29,399 - INFO - Testing model: mistralai/Mistral-7B
2025-01-13 15:56:29,401 - DEBUG - Starting new HTTPS connection (13): huggingface.co:443
2025-01-13 15:58:29,532 - DEBUG - Starting new HTTPS connection (14): huggingface.co:443
2025-01-13 16:00:29,676 - ERROR - Failed to test model mistralai/Mistral-7B: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like mistralai/Mistral-7B is not the path to a directory containing a file named config.json.
Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.
2025-01-13 16:00:29,686 - DEBUG - Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
socket.timeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 488, in _make_request
    raise new_e
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 1093, in _validate_conn
    conn.connect()
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connection.py", line 704, in connect
    self.sock = sock = self._new_conn()
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connection.py", line 207, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x7f372808f9d0>, 'Connection to huggingface.co timed out. (connect timeout=10)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /mistralai/Mistral-7B/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f372808f9d0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1374, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1294, in get_hf_file_metadata
    r = _request_wrapper(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 278, in _request_wrapper
    response = _request_wrapper(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 301, in _request_wrapper
    response = get_session().request(method=method, url=url, **params)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/utils/_http.py", line 93, in send
    return super().send(request, *args, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/requests/adapters.py", line 688, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /mistralai/Mistral-7B/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f372808f9d0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))"), '(Request ID: 357ae676-dbe3-4fbb-a37b-69a5cc05c8b2)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 860, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 967, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1485, in _raise_on_head_call_error
    raise LocalEntryNotFoundError(
huggingface_hub.errors.LocalEntryNotFoundError: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5268h/LLM-RSA-Project/run_experiments.py", line 45, in main
    model, tokenizer = load_model_and_tokenizer(model_name)
  File "/home/hpc/iwi5/iwi5268h/LLM-RSA-Project/models/models.py", line 6, in load_model_and_tokenizer
    model = AutoModel.from_pretrained(model_name)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 526, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py", line 1021, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/configuration_utils.py", line 590, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/configuration_utils.py", line 649, in _get_config_dict
    resolved_config_file = cached_file(
  File "/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/transformers/utils/hub.py", line 446, in cached_file
    raise EnvironmentError(
OSError: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like mistralai/Mistral-7B is not the path to a directory containing a file named config.json.
Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.

2025-01-13 16:00:29,686 - INFO - Testing model: tiiuae/falcon-7b
2025-01-13 16:00:29,688 - DEBUG - Starting new HTTPS connection (15): huggingface.co:443
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:15<00:15, 15.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:21<00:00,  9.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:21<00:00, 10.86s/it]
2025-01-13 16:02:51,733 - DEBUG - Starting new HTTPS connection (16): huggingface.co:443
2025-01-13 16:04:52,437 - DEBUG - Loaded model and tokenizer for tiiuae/falcon-7b
2025-01-13 16:04:52,437 - INFO - Running layer identification experiment for model: tiiuae/falcon-7b
2025-01-13 16:04:52,439 - DEBUG - Starting new HTTPS connection (17): huggingface.co:443
2025-01-13 16:06:52,583 - DEBUG - Starting new HTTPS connection (3): s3.amazonaws.com:443
2025-01-13 16:07:16,616 - DEBUG - Starting new HTTPS connection (2): datasets-server.huggingface.co:443
2025-01-13 16:13:57,039 - DEBUG - Starting new HTTPS connection (4): s3.amazonaws.com:443
2025-01-13 16:14:21,077 - DEBUG - Starting new HTTPS connection (18): huggingface.co:443
Using the latest cached version of the module from /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed (last modified on Thu Jan  9 11:51:10 2025) since it couldn't be found locally at super_glue, or remotely on the Hugging Face Hub.
2025-01-13 16:16:21,207 - WARNING - Using the latest cached version of the module from /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed (last modified on Thu Jan  9 11:51:10 2025) since it couldn't be found locally at super_glue, or remotely on the Hugging Face Hub.
2025-01-13 16:16:21,209 - DEBUG - Attempting to acquire lock 139875185208960 on /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue.lock
2025-01-13 16:16:21,236 - DEBUG - Lock 139875185208960 acquired on /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue.lock
2025-01-13 16:16:21,236 - DEBUG - Attempting to release lock 139875185208960 on /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue.lock
2025-01-13 16:16:21,237 - DEBUG - Lock 139875185208960 released on /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue.lock
2025-01-13 16:16:21,279 - DEBUG - Attempting to acquire lock 139874262188384 on /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/_home_hpc_iwi5_iwi5268h_.cache_huggingface_datasets_super_glue_wic_1.0.3_bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed.lock
2025-01-13 16:16:21,344 - DEBUG - Lock 139874262188384 acquired on /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/_home_hpc_iwi5_iwi5268h_.cache_huggingface_datasets_super_glue_wic_1.0.3_bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed.lock
2025-01-13 16:16:21,347 - DEBUG - open file: /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/dataset_info.json
2025-01-13 16:16:21,348 - DEBUG - Attempting to release lock 139874262188384 on /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/_home_hpc_iwi5_iwi5268h_.cache_huggingface_datasets_super_glue_wic_1.0.3_bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed.lock
2025-01-13 16:16:21,348 - DEBUG - Lock 139874262188384 released on /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/_home_hpc_iwi5_iwi5268h_.cache_huggingface_datasets_super_glue_wic_1.0.3_bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed.lock
2025-01-13 16:16:21,349 - DEBUG - Attempting to acquire lock 139874871773792 on /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue.lock
2025-01-13 16:16:21,351 - DEBUG - Lock 139874871773792 acquired on /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue.lock
2025-01-13 16:16:21,377 - DEBUG - Attempting to release lock 139874871773792 on /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue.lock
2025-01-13 16:16:21,378 - DEBUG - Lock 139874871773792 released on /home/hpc/iwi5/iwi5268h/.cache/huggingface/modules/datasets_modules/datasets/super_glue.lock
2025-01-13 16:16:21,379 - DEBUG - Attempting to acquire lock 139874262189824 on /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed_builder.lock
2025-01-13 16:16:21,417 - DEBUG - Lock 139874262189824 acquired on /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed_builder.lock
2025-01-13 16:16:21,418 - DEBUG - open file: /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed/dataset_info.json
2025-01-13 16:16:21,419 - DEBUG - Attempting to release lock 139874262189824 on /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed_builder.lock
2025-01-13 16:16:21,419 - DEBUG - Lock 139874262189824 released on /home/hpc/iwi5/iwi5268h/.cache/huggingface/datasets/super_glue/wic/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed_builder.lock
2025-01-13 16:16:21,747 - DEBUG - Loaded and prepared dataset: wic, split: train
2025-01-13 16:16:21,772 - DEBUG - Processing layer 0
/home/hpc/iwi5/iwi5268h/miniconda3/envs/llm_rsa_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
2025-01-13 17:23:16,902 - INFO - Layer 0 - Accuracy: 0.654, F1 Score: 0.654
2025-01-13 17:23:16,913 - DEBUG - Processing layer 1
/var/tmp/slurmd_spool/job972392/slurm_script: line 23: 2446251 Killed                  python run_experiments.py
slurmstepd: error: Detected 1 oom_kill event in StepId=972392.batch. Some of the step tasks have been OOM Killed.
