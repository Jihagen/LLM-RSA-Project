{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 1 but got size 3 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     11\u001b[0m samples \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m2\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m3\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m4\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m5\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[39m# 1) Compare different models activation per layer\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m##compare_activations_per_layer(models, texts)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[39m# 2) Compare different models activation globally per sample\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m compare_activations_per_sample(models, samples)\n",
      "File \u001b[0;32m~/LLM RSA Project/experiments.py:34\u001b[0m, in \u001b[0;36mcompare_activations_per_sample\u001b[0;34m(models, samples)\u001b[0m\n\u001b[1;32m     31\u001b[0m     model_labels\u001b[39m.\u001b[39mextend([model_name] \u001b[39m*\u001b[39m first_layer_activation\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m     33\u001b[0m \u001b[39m# Concatenate activations across models\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m combined_activations \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat(activations_by_model, dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     35\u001b[0m combined_rdm \u001b[39m=\u001b[39m compute_rdm(combined_activations)\n\u001b[1;32m     37\u001b[0m \u001b[39m# Perform MDS on the combined RDM\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 1 but got size 3 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "from experiments import  compare_activations_per_sample,compare_activations_per_sample\n",
    "\n",
    "models = [\"gpt2\", \"bert-base-uncased\"]\n",
    "texts = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Artificial intelligence is transforming the world.\",\n",
    "    \"Data science combines domain expertise and programming skills.\",\n",
    "    \"Machine learning enables computers to learn from data.\",\n",
    "    \"Natural language processing helps computers understand human language.\"\n",
    "]\n",
    "samples = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "\n",
    "# 1) Compare different models activation per layer\n",
    "##compare_activations_per_layer(models, texts)\n",
    "\n",
    "# 2) Compare different models activation globally per sample\n",
    "compare_activations_per_sample(models, samples)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_rsa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
